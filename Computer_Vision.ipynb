{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdmbbOxUyhr1qD1LZYAkR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satorumi/Machine-Learning/blob/main/Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrsW_Crj9K76"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USO7UqGI9S8k"
      },
      "source": [
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MHLq6bw8h3P"
      },
      "source": [
        "import cv2 as cv\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import math\n",
        "import os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBDha0Bm9aLR"
      },
      "source": [
        "#### Hand-Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXtX-A999Z1A"
      },
      "source": [
        "capture = cv.VideoCapture(1)\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands() # keep default parameter\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "while True:\n",
        "  _, img = capture.read()\n",
        "  imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  results = hands.process(imgRGB)\n",
        "  h, w, c = img.shape\n",
        "\n",
        "  if results.multi_hand_landmarks #if detected multi hand\n",
        "    for hand_lm in results.multi_hand_landmarks:\n",
        "      for index, lm in enumerate(hand_lm.landmark): # each landmark has x, y, z values\n",
        "        cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "        if index == 4: # the tip of the thumb\n",
        "          cv.circle(img, 25, (0,0,255), -1) # draw a circle\n",
        "      # draw connected line on detected hand\n",
        "      mpDraw.draw_landmarks(img, hand_lm, mpHands.HAND_CONNECTIONS) \n",
        "\n",
        "  # compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previoud_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, str(int(fps)), org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,255), thickness=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHgG2_nrHF7z"
      },
      "source": [
        "Hand-tracking Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZlWYieHEJk"
      },
      "source": [
        "class handDetector():\n",
        "  def __init__(self, mode=False, max_hand=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
        "    self.mode = mode\n",
        "    self.max_hand = max_hand\n",
        "    self.min_detection_confidence=min_detection_confidence\n",
        "    self.min_tracking_confidence=min_tracking_confidence\n",
        "\n",
        "    self.mpHands = mp.solutions.hands\n",
        "    self.hands = self.mpHands.Hands(self.mode, self.max_hand, self.min_detection_confidence, self.min_tracking_confidence)\n",
        "    self.mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "  def hand_detect(self, img, draw=True):\n",
        "    imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    self.results = self.hands.process(imgRGB)\n",
        "    h, w, c = img.shape\n",
        "\n",
        "    if self.results.multi_hand_landmarks \n",
        "      for hand_lm in self.results.multi_hand_landmarks:\n",
        "        if draw:\n",
        "          self.mpDraw.draw_landmarks(img, hand_lm, mpHands.HAND_CONNECTIONS) \n",
        "      return img\n",
        "\n",
        "  def landmarks_detect(self, img, landmark_num=0, draw=True):\n",
        "    landmarks = []\n",
        "    if self.results.multi_hand_landmarks:\n",
        "      hand = self.results.multi_hand_landmarks[landmark_num]\n",
        "      for index, lm in enumerate(hand.landmark): \n",
        "          cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "          landmarks.append([id, cx, cy])\n",
        "          if draw: \n",
        "            cv.circle(img, 25, (0,0,255), -1) \n",
        "    return landmarks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnmK6y0Mpz_"
      },
      "source": [
        "prev_time = 0\n",
        "capture = cv.VideoCapture(1)\n",
        "handDetector = handDetector()\n",
        "while True:\n",
        "  _, img = capture.read()\n",
        "  handDetect.hand_detect(img)\n",
        "  landmarks = handDetect.landmark_detect(img)\n",
        "  if landmarks:\n",
        "    print(landmarks[0]) # print location of specific landmark\n",
        "\n",
        "  cur_time = time.time()\n",
        "  fps = 1 / (cur_time-prev_time)\n",
        "  prev_time = cur_time\n",
        "  cv.putText(img, str(int(fps)), org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,255), thickness=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLCtJIdiP5rt"
      },
      "source": [
        "####Pose Estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AccDZ-75Pzir"
      },
      "source": [
        "cap = cv.VideoCapture('video_path')\n",
        "mpPose = mp.solution.pose\n",
        "pose = mpPose.Pose()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  results = pose.process(imgRGB)\n",
        "  w, h, c = img.shape\n",
        "  \n",
        "  landmarks = []\n",
        "  if result.pose_landmarks:\n",
        "    for index, lm in result.pose_landmarks:\n",
        "      cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "      landmarks.append(index, cx, cy, lm.z])\n",
        "      if index == 2: # left-eye\n",
        "        cv.circle(img, (cx,cy), radius=10, (0,0,255), 1)\n",
        "    mpDraw.draw_landmarks(img, result.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
        "\n",
        "  #compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previous_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, str(int(fps)), org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,255), thickness=2)\n",
        "  cv.waitKey(1)\n",
        "\n",
        "print(landmarks[14])  # the elblow\n",
        "cv.circle(img, (landmarks[14][1], landmarks[14][2]),  15, (0,0,255), -1) # tracking the elbow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC6T9a4B1UQy"
      },
      "source": [
        "Pose Estimation Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F2n0XMJ1Wnh"
      },
      "source": [
        "class poseDetector():\n",
        "    def __init__(self, mode=False, upBodyOnly=False, smooth=True,\n",
        "                 detectionConfidence=0.5, trackingConfidence=0.5):\n",
        "        self.mode = mode\n",
        "        self.upBodyOnly = upBodyOnly\n",
        "        self.smooth = smooth\n",
        "        self.detectionConfidence = detectionConfidence\n",
        "        self.trackingConfidence = trackingConfidence\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.mpPose = mp.solutions.pose\n",
        "        self.pose = self.mpPose.Pose(self.mode, self.upBodyOnly, self.smooth, self.detectionConfidence, self.trackingConfidence)\n",
        "\n",
        "    def pose_detect(self, img, draw=True):\n",
        "      imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "      self.results = self.pose.process(imgRGB)\n",
        "      if self.results.pose_landmarks:\n",
        "        if draw:\n",
        "          mpDraw.draw_landmarks(img, self.results.pose_landmarks, self.mpPose.POSE_CONNECTIONS)\n",
        "\n",
        "    def landmark_detect(self, img, draw=True):\n",
        "      self.landmarks = []\n",
        "      if self.results.pose_landmarks::\n",
        "        for index, lm in self.results.pose_landmarks:\n",
        "          h, w, c = img.shape\n",
        "          cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "          self.landmarks.append([index, cx, cy])\n",
        "          if draw:\n",
        "            cv.circle(img, (cx, cy), 5, (255, 0, 0), -1)\n",
        "      return self.landmarks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLpbqsCljs6f"
      },
      "source": [
        "#### Face Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yVbiS0Mtjzwy",
        "outputId": "3d10f0cb-80f1-4627-a4ff-ed4bae549647"
      },
      "source": [
        "previous_time = 0\n",
        "cap = cv.VideoCapture('video_path')\n",
        "mpFaceDetection = mp.solution.face_detection\n",
        "faceDetection = mpFaceDetection.FaceDetection()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  results = faceDetection.process(imgRGB)\n",
        "  h, w, c = img.shape\n",
        "  \n",
        "  detections = {}\n",
        "  if results.detections:\n",
        "    for index, detection in enumerate(results.detections):\n",
        "      box = detection.location_data.relative_bounding_box # acees to info in dict\n",
        "      x, y, w, h = int(box.xmin * w), int(box.ymin * h),\n",
        "                   int(box.width * w), int(box.height * h)\n",
        "      x1, y1 = x + w, y + h\n",
        "\n",
        "      # draw rectangle box around face\n",
        "      cv.rectangle(img, (x, y), (w, h), (255, 0, 255), 2)\n",
        "      cv.line(img, (x, y), (x, y+20), (255, 0, 255), 5)\n",
        "      cv.line(img, (x, y), (x+20, y), (255, 0, 255), 5)\n",
        "      # display detection score on top of box\n",
        "      cv.putText(img, f'{int(detection_score[0]/100}%',\n",
        "                (x, y - 20), cv.FONT_HERSHEY_PLAIN,\n",
        "                3, (255, 0, 255), 2) \n",
        "\n",
        "  \n",
        "  # compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previous_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, str(int(fps)), org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,255), thickness=2)\n",
        "  cv.waitKey(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f7a6b6260e5d>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    int(box.width * w), int(box.height * h)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2S7KsIV-zWc"
      },
      "source": [
        "####Face Mesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlhlgnjl-2sR"
      },
      "source": [
        "cap = cv.VideoCapture('video_path')\n",
        "mpFaceMesh = mp.solution.face_mesh\n",
        "FaceMesh = mpFaceMesh.FaceMesh(max_num_face=2)\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "drawSpec = mpDraw.DrawingSpec(thickness=2, circle_radius=1) # face display\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  results = faceDetection.process(imgRGB)\n",
        "  h, w, c = img.shape\n",
        "\n",
        "  faces = []\n",
        "  if results.multi_face_landmarks:\n",
        "    for face_lms in results.multi_face_landmarks:\n",
        "      mpDraw.draw_landmarks(img, face_lms, mp.FaceMesh.FACE_CONNECTIONS)\n",
        "      \n",
        "      landmarks = []\n",
        "      for index, lm in face_lms.landmark:\n",
        "        x, y = int(lm.x * w), int(lm.y * h)\n",
        "        landmarks.append([index, x, y])\n",
        "        # display idex of landmark\n",
        "        cv.putText(img, str(index), (x, y), cv.FONT_HERSHEY_COMPLEX, 0.5, (0,255,0), 3)\n",
        "      faces.append(landmarks)\n",
        "  \n",
        "\n",
        "  # compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previoud_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, f'FPS: {str(int(fps))}', org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,255), thickness=2)\n",
        "  cv.waitKey(1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gVNasXrFuxZ"
      },
      "source": [
        "#### Project #1 - Gesture Control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uptdlFc1OL0B"
      },
      "source": [
        "from ctypes import cast, POINTER\n",
        "from comtypes import CLSCTX_ALL\n",
        "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAB5z4pGGIyM"
      },
      "source": [
        "cap = cv.CaptureVideo(0)\n",
        "\n",
        "# define volume\n",
        "devices = AudioUtilities.GetSpeakers()\n",
        "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
        "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
        "volRange = volume.GetVolumeRange()\n",
        "minVol = volRange[0] # - 65\n",
        "maxVol = volRange[1] # 0\n",
        "vol = 0\n",
        "volBar = 400\n",
        "volPer = 0 # default volume percentage\n",
        "\n",
        "camera_width, camera_height = 1280, 720 # define camera size\n",
        "# set camera size\n",
        "cap.set(3, camera_width)\n",
        "cap.set(4, camera_height)\n",
        "previous_time = 0\n",
        "\n",
        "# using HandTracking Module\n",
        "handDetector = handDetector()\n",
        "\n",
        "while True:\n",
        "  _, img = capture.read()\n",
        "  handDetect.hand_detect(img)\n",
        "  landmarks = handDetect.landmarks_detect(img, draw=False)\n",
        "  if landmarks: # if not None\n",
        "    # get x, y position of specific landmark\n",
        "    x1, y1 = landmarks[4][1], landmarks[4][2]  # the thumb\n",
        "    x2, y2 = landmarks[8][1], landmarks[8][2] # index finger\n",
        "    cx, cy = (x1+x2) //2, (x1+x2) //2 # get the midpoint\n",
        "\n",
        "    cv.circle(img, (x1, y1), 7, (0, 0, 255), -1) # circle at thumb\n",
        "    cv.circle(img, (x2, y2), 7, (0, 0, 255), -1) # circle at index finger\n",
        "    cv.circle(img, (cx, cy), 7, (0, 0, 255), -1) # circle in the middle\n",
        "    cv.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "    length = math.hypot(x2 - x1, y2 - y1) # distance bewtween two fingers\n",
        "    if length < 50:  # change color if smaller distance\n",
        "      cv.circle(img, (cx, cy), 7, (0, 255, 0), -1)\n",
        "\n",
        "    # hand range from 50 - 300\n",
        "    # vol range -65 - 0\n",
        "\n",
        "  vol = np.interp(length, [50, 300], [minVol, max_Val])\n",
        "  volBar = np.interp(length, [50, 300], [400, 150]) # range for bar vol\n",
        "  volPer = np.interp(length, [50, 300], [0, 100])\n",
        "\n",
        "  volume.SetMasterVolumeLevel(vol, None)\n",
        "\n",
        "    # create the volume bar on the image\n",
        "  cv.rectangle(img, (50, 150), (85, 400), (255,0,0), 3)\n",
        "  cv.rectangle(img, (50, int(vol)), (85, 400), (255,0,0), 3)\n",
        "  # display vol percentage below vol bar\n",
        "  cv.putText(img, f'{int(volPer)}%', org=(40, 450), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,0), thickness=2)\n",
        "  \n",
        "  # compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previous_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, f'FPS: {str(int(fps))}', org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,0), thickness=2)\n",
        "  cv.waitKey(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_kWZZfiVuLj"
      },
      "source": [
        "# update handDetector class\n",
        "class handDetector():\n",
        "  def __init__(self, mode=False, max_hand=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
        "    # define congifure\n",
        "    self.mode = mode\n",
        "    self.max_hand = max_hand\n",
        "    self.min_detection_confidence=min_detection_confidence\n",
        "    self.min_tracking_confidence=min_tracking_confidence\n",
        "\n",
        "    self.mpHands = mp.solutions.hands\n",
        "    self.hands = self.mpHands.Hands(self.mode, self.max_hand, self.min_detection_confidence, self.min_tracking_confidence)\n",
        "    self.mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "  def hand_detect(self, img, draw=True):\n",
        "    imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    self.results = self.hands.process(imgRGB)\n",
        "\n",
        "    if self.results.multi_hand_landmarks \n",
        "      for hand_lm in self.results.multi_hand_landmarks:\n",
        "        if draw:\n",
        "          self.mpDraw.draw_landmarks(img, hand_lm, mpHands.HAND_CONNECTIONS) \n",
        "      return img\n",
        "\n",
        "  def landmarks_detect(self, img, landmark_num=0, draw=True):\n",
        "    self.landmarks = [] # a list to store all landmarks\n",
        "\n",
        "    if self.results.multi_hand_landmarks:\n",
        "      hand = self.results.multi_hand_landmarks[landmark_num]\n",
        "      h, w, c = img.shape\n",
        "      for index, lm in enumerate(hand.landmark): \n",
        "          cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "          self.landmarks.append([id, cx, cy])\n",
        "          if draw: \n",
        "             cv2.circle(img, (cx, cy), 5, (255, 0, 255), -1) \n",
        "    return self.landmarks\n",
        "\n",
        "  def find_distance(self, img, point1, point2, draw=True):\n",
        "    x1, y1 = self.landmarks[point1][1], self.landmarks[point1][2]\n",
        "    x2, y2 = self.landmarks[point2][1], self.landmarks[point2][2]\n",
        "    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2 # compute midpoint between two points\n",
        "    if draw:\n",
        "      cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED) # point 1\n",
        "      cv2.circle(img, (x2, y2), 15, (255, 0, 255), cv2.FILLED) # point 2\n",
        "      cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3) # line connect\n",
        "      cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED) # middle point \n",
        "    distance = math.hypot(x2 - x1, y2 - y1) # distance between\n",
        "    locations = [x1, y1, x2, y2, cx, cy]\n",
        "    return distance, img, locations\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz_ZyEJuYwg0"
      },
      "source": [
        "#### Project #2: Finger Counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AunBIAX1Yvgo"
      },
      "source": [
        "cap = cv.CaptureVideo(0)\n",
        "camera_width, camera_height = 1280, 720 # define camera size\n",
        "# set camera size\n",
        "cap.set(3, camera_width)\n",
        "cap.set(4, camera_height)\n",
        "previous_time = 0\n",
        "\n",
        "folder_path = r'folder_path' # all images with hand counting from 0-5\n",
        "folder = os.listdir(folder_path)\n",
        "img_list = []\n",
        "for img_path in folder:\n",
        "  img = cv.imread(f'{folder_path}/{img_path}') # image path\n",
        "  img_list.append(img)\n",
        " \n",
        "# using HandTracking Module\n",
        "handDetector = handDetector()\n",
        "\n",
        "while True:\n",
        "  _, img = capture.read()\n",
        "  handDetect.hand_detect(img)\n",
        "  landmarks = handDetect.landmarks_detect(img, draw=False)\n",
        "  if landmarks: # if not None\n",
        "  \n",
        "    finger_points = [4, 8, 12, 16, 20] # all fingers tips\n",
        "    counting = 0 # keep track of counting finger\n",
        "    for point in finger_points:\n",
        "      if point == 4: # the thumb\n",
        "        if landmarks[4][1] > landmarks[3][1]: # check if the tips is on the righ\n",
        "          counting += 1 # increase the counting finger \n",
        "      elif landmarks[point][2] < landmarks[point-2][2]:\n",
        "        counting += 1 # increase the counting finger \n",
        "\n",
        "    # display counting image on top-left\n",
        "    h, w, c = img_list[1].shape\n",
        "    img[0:w, 0:h] = img_list[counting]\n",
        "    # display the number of finger\n",
        "    cv.rectangle(img, (0,200), (0,350), (0,0,255), -1)\n",
        "    cv.putText(img, str(counting), (30, 170), cv.FONT_HERSHEY_COMPLEX, 1.2, (255,0,0), 20)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  # compute fps\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previous_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, f'FPS: {str(int(fps))}', org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,0), thickness=2)\n",
        "  cv.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8piRw7zbq_"
      },
      "source": [
        "# update Hand tracking module\n",
        "def finger_counter(self, img, counting_img=True, draw=True):\n",
        "  folder_path = r'folder_path' # all images with hand counting from 0-5\n",
        "  folder = os.listdir(folder_path)\n",
        "  img_list = []\n",
        "  for img_path in folder:\n",
        "    img = cv.imread(f'{folder_path}/{img_path}') # image path\n",
        "    img_list.append(img)\n",
        "\n",
        "  if self.landmarks:  \n",
        "    finger_points = [4, 8, 12, 16, 20]\n",
        "    counting = 0 \n",
        "    for point in finger_points:\n",
        "      if point == 4:\n",
        "        if landmarks[4][1] > landmarks[3][1]: \n",
        "          counting += 1 \n",
        "      elif landmarks[point][2] < landmarks[point-2][2]:\n",
        "        counting += 1 \n",
        "\n",
        "    if counting_img:\n",
        "      h, w, c = img_list[1].shape\n",
        "      img[0:w, 0:h] = img_list[counting]\n",
        "    if draw:\n",
        "      cv.rectangle(img, (0,200), (0,350), (0,0,255), -1)\n",
        "      cv.putText(img, str(counting), (30, 170), cv.FONT_HERSHEY_COMPLEX, 1.2, (255,0,0), 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTQPE_58zZjQ"
      },
      "source": [
        "####Project #3 - AI Personal Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B0tXrs135oU"
      },
      "source": [
        "# Update PoseDetector Module\n",
        "def angle_detect(self, img, point1, point2, point3, bar=True, draw=True):\n",
        "  # Get the landmarks\n",
        "  x1, y1 = self.lmList[point1][1:]\n",
        "  x2, y2 = self.lmList[point2][1:]\n",
        "  x3, y3 = self.lmList[point3][1:]\n",
        "  points = [[x1, y1], [x2, y2], [x3, y3]]\n",
        "\n",
        "  # Calculate the Angle\n",
        "  self.angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -\n",
        "                      math.atan2(y1 - y2, x1 - x2))\n",
        "  if self.angle < 0:\n",
        "    self.angle += 360\n",
        "\n",
        "  if draw:\n",
        "    cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
        "    cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n",
        "\n",
        "    for x, y in points: # loop through every point\n",
        "      cv2.circle(img, (x, y), 8, (0, 0, 255), cv2.FILLED)\n",
        "      cv2.circle(img, (x, y), 11, (0, 0, 255), 2)\n",
        "\n",
        "    cv2.putText(img, str(int(angle)), (x2 - 40, y2 + 40),\n",
        "                cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
        " \n",
        "  return angle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhATZ7nvBKm_"
      },
      "source": [
        "def reps_track(self, img, bar=True, draw=True):\n",
        "  global reps\n",
        "  direction = 0\n",
        "  per = np.interp(self.angle, (210, 310), (0,100))\n",
        "  \n",
        "  # count number of rep in an exercise\n",
        "  # example, dumbell curls\n",
        "  if per == 100 and direction == 0:\n",
        "    reps += 0.5\n",
        "    direction = 1\n",
        "    color = (0,255,0)\n",
        "  if per == 0 and direction == 1:\n",
        "    reps += 0.5\n",
        "    direction = 0\n",
        "    color = (0,0,255)\n",
        "    \n",
        "  # display reps\n",
        "  cv2.rectangle(img, (0, 450), (250, 720), (0, 255, 0), cv2.FILLED)\n",
        "  cv2.putText(img, f'Reps:{str(self.reps)}', (45, 650),\n",
        "                cv2.FONT_HERSHEY_PLAIN, 1.5, (0,0,255), 2) \n",
        "  \n",
        "  if bar: # display the bar, represent action progress\n",
        "    bar = np.interp(self.angle, (210, 310), (650, 100))\n",
        "    cv2.rectangle(img, (1100, 100), (1175, 650), color, 3)\n",
        "    cv2.rectangle(img, (1100, int(bar)), (1175, 650), color, cv2.FILLED)\n",
        "    cv2.putText(img, f'{int(per)} %', (1100, 75), cv2.FONT_HERSHEY_PLAIN, 4, (0,0,255), 4)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "192bEAC0zaGE",
        "outputId": "ad2cc128-785e-4322-9d60-e3373023217e"
      },
      "source": [
        "cap = cv.VideoCapture('video_path')\n",
        "poseDetector = poseDetector() # using pose detector module\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  img = cv.resize(img, 1280, 720)\n",
        "  cv.waitKey(1)\n",
        "  poseDetector.pose_detect(img, draw=False)\n",
        "  landmarks = poseDetector.landmark_detect(img, draw=False)\n",
        "\n",
        "  if landmarks: # not None\n",
        "    poseDetector.angle_detect(img, 20, 24, 14)\n",
        "    reps = 0\n",
        "    reps_track(self, img)  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-561b48e3d87d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mposeDetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposeDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPXZEjXPGtE"
      },
      "source": [
        "####Project #4 - AI Virtual Painter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Lf40LsW_A3"
      },
      "source": [
        "# update hand tracking module\n",
        "self.finger_tips = [4, 8, 12, 16, 20] # define tips of all fingers\n",
        "\n",
        "def finger_up(self, img):\n",
        "  fingers_up = []  # store all fingers status\n",
        "  for i in range(5):\n",
        "      # check if Thumb on the right\n",
        "    if i == 0 and self.landmarks[self.finger_tips[0]][1] > self.landmarks[self.finger_tips[0] - 1][1]:\n",
        "      fingers.append(True)\n",
        "    elif self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
        "      fingers.append(True)\n",
        "    else: # finger is not up\n",
        "      fingers.append(False)\n",
        "\n",
        "    return fingers_up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60T-pE3UPO00"
      },
      "source": [
        "# using canvas to create painting board\n",
        "folder_path = r'folder_path' # contain 4 images of 3 brushes and one eraser\n",
        "img_paths = os.listdir(folderpath)\n",
        "img_list = []\n",
        "for img_path in imgg_paths:\n",
        "  img = cv.read(f'{folder_path}/{img_path}')\n",
        "  img_list.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPQNcyLcR9Vq"
      },
      "source": [
        "cap = cv.CaptureVideo(0)\n",
        "camera_width, camera_height = 640, 480 # define camera size\n",
        "# set camera size\n",
        "cap.set(3, camera_width)\n",
        "cap.set(4, camera_height)\n",
        "previous_time = 0\n",
        "\n",
        "\n",
        "header = img_list[0] # the default img\n",
        "handDetector = handDetector(0.85) # change confidence level\n",
        "brush_thicknesss = 2\n",
        "canvas = np.zeros(shape=(640,480,3), dtype=np.uint8) # the drawing image\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  \n",
        "  img = cv.flip(img, 1) # flip image \n",
        "  \n",
        "  landmarks = handDetector.landmarks_detect(img, draw=False)\n",
        "  if landmarks: # if hand is detected\n",
        "    x1, y1 = landmarks[8][1:] # tip of index finger\n",
        "    x2, y2 = landmarks[12][1:] # tip of middle finger\n",
        "    \n",
        "    fingers_up = handDetector.finger_up(img) \n",
        "\n",
        "    # selection mode\n",
        "    if y1 < 125:\n",
        "      if fingers_up[1] and fingers_up[2]: # both index & middle are up \n",
        "        prev_x, prev_y = 0, 0 # default location of hand\n",
        "        if 250 < x1 < 450: # select purple brush\n",
        "          header = img_list[1] \n",
        "          draw_color = (255,0,255)\n",
        "        elif 800 < x1 < 950: # select green brush\n",
        "          header = img_list[2]  \n",
        "          draw_color = (0,0,255)\n",
        "        elif 800 < x1 < 950: # select thrid brush\n",
        "          header = img_list[3]\n",
        "          draw_color = (255,0,0)\n",
        "        elif 1050 < x1 < 1200: # select eraser \n",
        "          header = img_list[4]\n",
        "          draw_color = (0,0,0)\n",
        "          eraser_thickness = 4\n",
        "\n",
        "    if fingers_up[1] and not fingers_up[2]: # only index is up -> drawing mode\n",
        "\n",
        "      if (prev_x and prev_y) == 0\n",
        "        prev_x, prev_y = x1, y1\n",
        "\n",
        "      if draw_color == (0,0,0): # eraser selected\n",
        "        cv.circle(img,  6, (x1, y1), draw_color, -1) # a circle on index finger\n",
        "        cv.line(canvas, (prev_x, prev_y), (x1, y1), draw_color, eraser_thickness)\n",
        "      else:\n",
        "        cv.circle(img,  6, (x1, y1), draw_color, -1) # a circle on index finger\n",
        "        cv.line(canvas, (prev_x, prev_y), (x1, y1), draw_color, brush_thickness)\n",
        "\n",
        "      prev_x, prev_y = x1, y1 # set previous to current point\n",
        "\n",
        "    gray_canvas = cv.cvtColor(canvas, cv.COLOR_BGR2GRAY) # convert color to gray\n",
        "    _, thresh = cv.threshold(gray_canvas, cv.THRESH_BINARY) # turn canvas to balck & white image\n",
        "    thresh = cv.cvtColor(thresh, cv.COLOR_GRAY2BGR) # convert to bgr color\n",
        "    img = cv.bitwise_and(img, thresh) # extract color appear in BOTH \n",
        "    img = cv.bitwise_or(img, canvas) # extract color appear in EITHER \n",
        "\n",
        "    img[0:125, 0:1280] = header # set the header image on-top\n",
        "    cv.imshow('Image', img)\n",
        "    cv.imshow('Canvas', canvas)\n",
        "    \n",
        "  cv.waitKey(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRbnrLTvq6LR"
      },
      "source": [
        "#### Project #5 - AI Virtual Mouse\n",
        "description: simply simulate mouse behavior by hand with previous built-in hand tracking module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRRuQH6PtK_2"
      },
      "source": [
        "!pip install autopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsWxaZcetP1v"
      },
      "source": [
        "import autopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKFrKDhMtSrS"
      },
      "source": [
        "cap = cv.CaptureVideo(0)\n",
        "camera_width, camera_height = 640, 480 # define camera size\n",
        "screen_width, screen_height = autopy.screen.size() # size of screen\n",
        "reduction = 100 # reduce frame to track mouse movement\n",
        "smooth_val = 7 # smoothing value to slow\n",
        "\n",
        "# set camera size\n",
        "cap.set(3, camera_width)\n",
        "cap.set(4, camera_height)\n",
        "previous_time = 0\n",
        "# using hand tracking module\n",
        "handDetector = handDetector()\n",
        "prev_x, prev_y = 0, 0\n",
        "cur_x, cur_y = 0, 0\n",
        "\n",
        "while True:\n",
        "  _, img = cap.read()\n",
        "  handDetector.hand_detect(img, draw=False)\n",
        "  landmarks = handDetector.landmarks_detect(img, draw=False)\n",
        "\n",
        "  if landmarks:\n",
        "    x1, y1 = landmarks[8][1:] # index finger\n",
        "    x2, y2 = landmarks[12][1:] # middle finger\n",
        "    fingers_up - handDetector.finger_up() # list of raising fingers\n",
        "\n",
        "    if fingers_up[1] and fingers_up[2]: # clicking mode\n",
        "      # check distance with class function\n",
        "      distance, _ , locations = find_distance(img, 8, 12, draw=False)\n",
        "      midpoint = locations[4:]\n",
        "\n",
        "      if distance < 40: # small distance\n",
        "        # cv.circle(img, (x1, y1), 10, (0,0,255), -1)\n",
        "        autopy.mouse.click() # click\n",
        "\n",
        "\n",
        "\n",
        "    if fingers_up[1]: # moving mode: only index finger is up\n",
        "      # w, h of mouse tracking area\n",
        "      track_w, track_h = camera_width - reduction, camera_height - reduction\n",
        "\n",
        "      # draw a rectangle around the mouse tracking area\n",
        "      cv.rectangle(img, (reduction, reduction), (track_w, track_h), (0,0,255), 2)\n",
        "      cv.circle(img, (x1, y1), 10, (0,0,255), -1)\n",
        "\n",
        "      # convert coordinates to screen size\n",
        "      cx = np.interp(x1, [0, track_w], [0, screen_width])\n",
        "      cy = np.interp(y1, [0, track_h], [0, screen_height])\n",
        "      \n",
        "      cur_x = prev_x + (cx - prev_x) / smooth_val\n",
        "      cur_y = prev_y + (cy - prev_y) / smooth_val\n",
        "\n",
        "      # move the mouse\n",
        "      autopy.mouse.move(screen_width-cur_x, cur_y) # flip it, when we move to the right it go to the right \n",
        "\n",
        "      # update previous location of x, y\n",
        "      prev_x, prev_y = cur_x, cur_y\n",
        "\n",
        "  # frame rate\n",
        "  current_time = time.time()\n",
        "  fps = 1/(current_time-previous_time)\n",
        "  previous_time = current_time\n",
        "  # display fps\n",
        "  cv.putText(img, f'FPS: {str(int(fps))}', org=(10, 50), fontFace=cv.FONT_HERSHEY_COMPLEX, \n",
        "             fontScale=1.2, color=(255,0,0), thickness=2)\n",
        "  cv.waitKey(1)\n",
        "\n",
        "  cv.waitKey(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}